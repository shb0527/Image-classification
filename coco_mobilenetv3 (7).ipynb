{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "following-bulgarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import zipfile\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import skimage.color\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "  tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44560d64-ec80-498d-a0c2-60273bdac7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n"
     ]
    }
   ],
   "source": [
    "#train_list\n",
    "dataDir='..'\n",
    "dataType='train2017'\n",
    "annFile='{}/datasets/coco_2017/annotations/instances_{}.json'.format(dataDir, dataType)\n",
    "coco=COCO(annFile)\n",
    "root_dir='../datasets/coco_2017/images/'\n",
    "set_name='train2017_resize224/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b16c70d6-57f6-44ca-ab9f-db38568b0e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118287"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_ids\n",
    "categories = coco.loadCats(coco.getCatIds())\n",
    "categories.sort(key=lambda x: x['id'])\n",
    "image_ids = coco.getImgIds()\n",
    "len(image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ecc5b54-aeab-43ab-b95f-baaee1ac5b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.30s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "#val_list\n",
    "dataDir='..'\n",
    "dataType2='val2017'\n",
    "annFile='{}/datasets/coco_2017/annotations/instances_{}.json'.format(dataDir, dataType2)\n",
    "coco2=COCO(annFile)\n",
    "root_dir2='../datasets/coco_2017/images/'\n",
    "set_name2='val2017_resize224/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fd44505-168c-4de6-aa0d-90c3b3f2d1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val_ids\n",
    "categories2 = coco2.loadCats(coco2.getCatIds())\n",
    "categories2.sort(key=lambda x: x['id'])\n",
    "image_ids2 = coco2.getImgIds()\n",
    "len(image_ids2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06c6b32f-e131-49ea-b1b7-f323b9a8a9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#category = 80\n",
    "category_dict = {(1,0), (2,1), (3,2), (4,3), (5,4), (6,5), (7,6), (8,7), (9,8), (10,9), (11,10), (13,11), (14, 12), (15, 13), (16, 14), (17, 15), (18, 16), (19, 17),\n",
    "(20, 18), (21, 19), (22, 20), (23, 21), (24, 22) , (25, 23), (27, 24), (28, 25), (31, 26), (32, 27), (33, 38), (34, 29), (35, 30), (36, 31), (37, 32), (38,33), (39, 34),\n",
    "(40, 35), (41, 36), (42, 37), (43 ,38), (44 , 39), (46 , 40), (47 ,41), (48,42), (49 ,43), (50 , 44), (51, 45), (52, 46),  (53, 47), (54 , 48), (55 , 49), (56, 50), (57 , 51),\n",
    "(58 , 52), (59 , 53), (60, 54), (61, 55), (62, 56), (63, 57), (64, 58), (65, 59), (67, 60), (70 , 61), (72, 62), (73 , 63), (74, 64), (75 , 65), (76 , 66), (77 , 67), (78 , 68),\n",
    "(79 , 69),(80 , 70), (81 , 71), (82 , 72), (84 , 73), (85 , 74), (86 , 75), (87, 76), (88 , 77), (89 , 78), (90 , 79)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e70a007-f450-4c24-ad4a-eb3186864a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#category = 10\n",
    "category_dict2 = {(1,0), (2,1), (3,1), (4,1), (5,1), (6,1), (7,1), (8,1), (9,1), (10,2), (11,2), (13,2), (14, 2), (15, 2), (16, 2), (17, 2), (18, 2), (19, 2),\n",
    "(20, 2), (21, 2), (22, 2), (23, 2), (24, 2) , (25, 2), (27, 3), (28, 3), (31, 3), (32, 3), (33, 3), (34, 3), (35, 3), (36, 3), (37, 3), (38,3), (39, 3),\n",
    "(40, 3), (41, 3), (42, 3), (43 ,3), (44 , 4), (46 , 4), (47 ,4), (48,4), (49 ,4), (50 , 4), (51, 4), (52, 5),  (53, 5), (54 , 5), (55 , 5), (56, 5), (57 , 5),\n",
    "(58 , 5), (59 , 5), (60, 5), (61, 5), (62, 6), (63, 6), (64, 6), (65, 6), (67, 6), (70 , 6), (72, 7), (73 , 7), (74, 7), (75 , 7), (76 , 7), (77 , 7), (78 , 8),\n",
    "(79 , 8),(80 , 8), (81 , 8), (82 , 8), (84 , 9), (85 , 9), (86 , 9), (87, 9), (88 , 9), (89 , 9), (90 , 9)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a24c874c-868a-4fd4-8384-1a3f22b0cc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_imagelist(num: int):\n",
    "    img_list = []\n",
    "    labels = []\n",
    "    index_list = []\n",
    "    for i in range(num):\n",
    "    \n",
    "        image_info = coco.loadImgs(image_ids[i])[0]\n",
    "        path = os.path.join(root_dir, set_name, image_info['file_name'])\n",
    "        img = Image.open(path)\n",
    "        imgarray = np.array(img)\n",
    "        annotations_ids =coco.getAnnIds(imgIds=image_ids[i], iscrowd=False)\n",
    "        if imgarray.ndim == 3 and annotations_ids:\n",
    "                \n",
    "                img_list.append(imgarray)\n",
    "                index_list.append(i)\n",
    "                coco_annotations = coco.loadAnns(annotations_ids)\n",
    "                areas =[]\n",
    "                areas.append(x['area'] for x in coco_annotations)\n",
    "                index = np.argmax(areas)\n",
    "                category_id = coco_annotations[index]['category_id']\n",
    "    \n",
    "                for c,d in category_dict:\n",
    "                    if c == category_id:\n",
    "                        label = [0 for i in range(80)]\n",
    "                        label[d] = 1\n",
    "                labels.append(label)  \n",
    "    return np.asarray(img_list), np.asarray(labels)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15d80fe1-a3b3-451d-8391-b171203656bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_multi_imagelist(num: int):\n",
    "    img_list = []\n",
    "\n",
    "\n",
    "    labels_list= []\n",
    "    index_list = []\n",
    "    for i in range(num):\n",
    "        \n",
    "        image_info = coco.loadImgs(image_ids[i])[0]\n",
    "        path = os.path.join(root_dir, set_name, image_info['file_name'])\n",
    "        img = Image.open(path)\n",
    "        imgarray = np.array(img)\n",
    "        annotations_ids =coco.getAnnIds(imgIds=image_ids[i], iscrowd=False)\n",
    "        label =[]\n",
    "        if imgarray.ndim == 3 and annotations_ids:\n",
    "                \n",
    "                img_list.append(imgarray)\n",
    "                \n",
    "                coco_annotations = coco.loadAnns(annotations_ids)\n",
    "                \n",
    "                label = [0 for i in range(80)]\n",
    "                for index in range(len(coco_annotations)):\n",
    "                    \n",
    "                    category_id = coco_annotations[index]['category_id']\n",
    "                \n",
    "                    for c,d in category_dict:\n",
    "                        if c == category_id:\n",
    "                            label[d] = 1\n",
    "                labels_list.append(label)\n",
    "        \n",
    "                    \n",
    "    return np.asarray(img_list), np.asarray(labels_list)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85260a6a-c173-4f4d-852a-0374030f3c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.878818429277145"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = create_multi_imagelist(10000)[1]\n",
    "A_list = []\n",
    "for a in A:\n",
    "    A_list.append(np.count_nonzero(a == 1))\n",
    "np.mean(A_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6eaf127b-3e92-4632-aece-dce9fbfb032e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_val_imagelist(num: int):\n",
    "    img_list = []\n",
    "    labels = []\n",
    "    index_list = []\n",
    "    for i in range(num):\n",
    "    \n",
    "        image_info = coco2.loadImgs(image_ids2[i])[0]\n",
    "        path = os.path.join(root_dir2, set_name2, image_info['file_name'])\n",
    "        img = Image.open(path)\n",
    "        imgarray = np.array(img)\n",
    "        annotations_ids =coco2.getAnnIds(imgIds=image_ids2[i], iscrowd=False)\n",
    "        if imgarray.ndim == 3 and annotations_ids:\n",
    "                \n",
    "                img_list.append(imgarray)\n",
    "                index_list.append(i)\n",
    "                coco_annotations = coco2.loadAnns(annotations_ids)\n",
    "                areas =[]\n",
    "                areas.append(x['area'] for x in coco_annotations)\n",
    "                index = np.argmax(areas)\n",
    "                category_id = coco_annotations[index]['category_id']\n",
    "    \n",
    "                for c,d in category_dict:\n",
    "                    if c == category_id:\n",
    "                        label = [0 for i in range(80)]\n",
    "                        label[d] = 1\n",
    "                labels.append(label)  \n",
    "    return np.asarray(img_list), np.asarray(labels)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45cf38e5-a7f6-4b5e-ba62-b35a75863a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_multi_val_imagelist(num: int):\n",
    "    img_list = []\n",
    "    labels_list = []\n",
    "    for i in range(num):\n",
    "    \n",
    "        image_info = coco2.loadImgs(image_ids2[i])[0]\n",
    "        path = os.path.join(root_dir2, set_name2, image_info['file_name'])\n",
    "        img = Image.open(path)\n",
    "        imgarray = np.array(img)\n",
    "        annotations_ids =coco2.getAnnIds(imgIds=image_ids2[i], iscrowd=False)\n",
    "        if imgarray.ndim == 3 and annotations_ids:\n",
    "                \n",
    "                img_list.append(imgarray)\n",
    "               \n",
    "                coco_annotations = coco2.loadAnns(annotations_ids)\n",
    "                \n",
    "                \n",
    "                label = [0 for i in range(80)]\n",
    "                for index in range(len(coco_annotations)):\n",
    "                    \n",
    "                    category_id = coco_annotations[index]['category_id']\n",
    "                    for c,d in category_dict:\n",
    "                        if c == category_id:\n",
    "                            label[d] = 1\n",
    "                labels_list.append(label)\n",
    "              \n",
    "    return np.asarray(img_list), np.asarray(labels_list)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf8a097d-c554-4087-9100-401391acdbff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59472, 224, 224, 3), (59472, 80))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = create_multi_imagelist(60000)\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "461c4c1f-dd79-4341-9fa7-e4462b9fc1fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4952, 224, 224, 3), (4952, 80))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, Y_test = create_multi_val_imagelist(5000)\n",
    "X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75854336-e0dd-49eb-9f7e-16f2b84ada38",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'coco' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-dd5cabb7b45f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_imagelist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-ff9b0ec3137f>\u001b[0m in \u001b[0;36mcreate_imagelist\u001b[0;34m(num)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mimage_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadImgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'coco' is not defined"
     ]
    }
   ],
   "source": [
    "X, Y = create_imagelist(10000)\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa775447-339e-4e0c-ae41-ef3038554e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(nrows=1,ncols=10,figsize=(20,20))\n",
    "for i in range(10):\n",
    "    ax[i].imshow(X[i+3000])\n",
    "    ax[i].axis('off')\n",
    "    for c,d in category_dict:\n",
    "        if d == np.argmax(Y[i+3000]):\n",
    "            print(c, end = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1691d718-0682-45cf-b650-b7b9e71b0a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "datagen= ImageDataGenerator(featurewise_center=True, fill_mode=\"nearest\")\n",
    "# train = datagen.flow(X, Y, batch_size=64)\n",
    "# len(train.next()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafdd171-686f-4d3a-8d1b-4ebeaf52fb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(nrows=1,ncols=10,figsize=(20,20))\n",
    "for i in range(10):\n",
    "    ax[i].imshow(X[i])\n",
    "    ax[i].axis('off')\n",
    "    \n",
    "    c_list = []\n",
    "    for x in np.where(Y[i] == 1):\n",
    "        for c,d in category_dict:\n",
    "            if d == x:\n",
    "                print(c, end= ' ')\n",
    "    \n",
    "            \n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3cc7845-4128-4b09-b013-49437abf7588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_swish(features):\n",
    "\n",
    "  \n",
    "  features = tf.convert_to_tensor(features)\n",
    "  fdtype = features.dtype\n",
    "  return features * tf.nn.relu6(features + tf.cast(3., fdtype)) * (1. / 6.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b717254-b501-4b15-82c3-577421b27dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def se_block(inputs, ch, ratio=16):\n",
    "\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(inputs)\n",
    "    x = tf.keras.layers.Dense(ch//ratio, activation='relu')(x)\n",
    "    y = tf.keras.layers.Dense(ch, activation='sigmoid')(x)\n",
    "    y = tf.keras.layers.multiply([inputs, y])\n",
    "    out = hard_swish(y)\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "269dfe6b-d097-40ac-8719-68e0cf65de9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dep_bn(inputs, filter : int, kernel :int, stride: int):\n",
    "\n",
    "  y = tf.keras.layers.Conv2D(filters = filter, kernel_size= kernel, strides= stride, padding= 'same')(inputs)\n",
    "  bn = tf.keras.layers.BatchNormalization(axis = 1)(y)\n",
    "  relu = tf.nn.relu6(bn)\n",
    "  \n",
    "  return relu \n",
    "\n",
    "\n",
    "def Inverted_residual_SEblock(x, filter : int, kernel: int, strides = int):\n",
    "\n",
    "\n",
    "    #pointwise\n",
    "    y = tf.keras.layers.Conv2D(filters = filter, kernel_size=  1, strides = strides, padding= 'same')(x)\n",
    "    bn = tf.keras.layers.BatchNormalization(axis = 1)(y)\n",
    "    y_p = tf.nn.relu6(bn)\n",
    "    \n",
    "    \n",
    "    #depthwise\n",
    "    y = tf.keras.layers.DepthwiseConv2D(kernel_size=  kernel, strides= strides, padding= 'same', depth_multiplier = 1)(y_p)\n",
    "    bn = tf.keras.layers.BatchNormalization(axis = 1)(y)\n",
    "    y_d = tf.nn.relu6(bn)\n",
    "   \n",
    "   \n",
    "    #pointwise\n",
    "    y = tf.keras.layers.Conv2D(filters = filter, kernel_size= 1, strides=strides, padding= 'same')(y)\n",
    "    y = tf.keras.layers.BatchNormalization(axis = 1)(y)\n",
    "    out = tf.keras.layers.ReLU()(y)\n",
    "\n",
    "    if strides == 1:\n",
    "        if x.shape[3] != filter : \n",
    "           x = tf.keras.layers.Conv2D(filters = filter, kernel_size = 1, strides = strides, padding = \"same\")(x)\n",
    "        out  = tf.keras.layers.Add()([x, out])\n",
    "   \n",
    "    y = se_block(out, filter)\n",
    "\n",
    "    #pointwise\n",
    "    y = tf.keras.layers.Conv2D(filters = filter, kernel_size= 1, strides=strides, padding= 'same')(y)\n",
    "    y = tf.keras.layers.BatchNormalization(axis = 1)(y)\n",
    "    out = tf.nn.relu6(y)\n",
    "\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c92dbe67-c3b5-4980-87d8-ab5e9d5be9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mobilenetV3(inputs):\n",
    "\n",
    "   x = dep_bn(inputs, 16, 3, 2)\n",
    "   x = Inverted_residual_SEblock(x, 16, 3, 1)\n",
    "   x = Inverted_residual_SEblock(x, 16, 3, 2)\n",
    "   x = Inverted_residual_SEblock(x, 24, 3, 1)\n",
    "   x = Inverted_residual_SEblock(x, 24, 5, 2)\n",
    "   x = Inverted_residual_SEblock(x, 40, 5, 1)\n",
    "   x = Inverted_residual_SEblock(x, 40, 5, 1)\n",
    "   x = Inverted_residual_SEblock(x, 40, 3, 2)\n",
    "   x = Inverted_residual_SEblock(x, 80, 3, 1)\n",
    "   x = Inverted_residual_SEblock(x, 80, 3, 1)\n",
    "   x = Inverted_residual_SEblock(x, 80, 3, 1)\n",
    "   x = Inverted_residual_SEblock(x, 80, 3, 1)\n",
    "   x = Inverted_residual_SEblock(x, 112, 3, 1)\n",
    "   x = Inverted_residual_SEblock(x, 112, 5, 1)\n",
    "   x = Inverted_residual_SEblock(x, 160, 5, 1)\n",
    "   x = dep_bn(x, 160, 1, 1)\n",
    "   \n",
    "   t = tf.keras.layers.AveragePooling2D(1)(x)\n",
    "   t = tf.keras.layers.Flatten()(t)\n",
    "   outputs = tf.keras.layers.Dense(80, activation='sigmoid')(t)\n",
    "   return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80ce05c9-a1e0-4a18-a5aa-9ef3a72eb1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(224,224,3))\n",
    "outputs = create_mobilenetV3(inputs)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "opt = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "model.compile(\n",
    "        optimizer=opt,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ec29ed7-fdfb-4ef8-bac0-90920f8cba62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model0712/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"model0712\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fb63da9-78f2-4df0-9e01-55d7a7cdca00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4952, 80)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def making_ypred(predictions):\n",
    "    pred2s = []\n",
    "    for pred in predictions:\n",
    "        pred2 = np.argsort(pred)[::-1]\n",
    "        for i in range(len(pred2)):\n",
    "            if pred2[i] < 3:\n",
    "                pred2[i] = 1\n",
    "                \n",
    "            else:\n",
    "                pred2[i] = 0\n",
    "        pred2s.append(pred2)\n",
    "    return pred2s\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "y_pred = np.asarray(making_ypred(predictions))\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bce6aed-b3ba-4553-b5c3-af5289f4a674",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-1911ead2f59f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m97\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_pred2\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)[97]\n",
    "y_pred2= np.argsort(y_pred)[::-1]\n",
    "print(np.argmax(y_pred))\n",
    "y_pred, y_pred2\n",
    "for i in range(len(y_pred2)):\n",
    "    if y_pred2[i] < 3:\n",
    "        y_pred2[i] = 1\n",
    "    else:\n",
    "        y_pred2[i] = 0\n",
    "y_pred2\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b438a993-7368-4a23-8972-a2e768d72575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4952, 80)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75a6466b-1b9d-44de-9fd8-02d7ddf72cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.models.load_model(\"model0713-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94655b60-8d3f-43bc-943b-fae5a55ee266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      1.00      0.70      2693\n",
      "           1       0.00      0.00      0.00       149\n",
      "           2       0.25      0.62      0.35       535\n",
      "           3       0.00      0.00      0.00       159\n",
      "           4       0.00      0.00      0.00        97\n",
      "           5       0.00      0.00      0.00       189\n",
      "           6       0.00      0.00      0.00       157\n",
      "           7       0.00      0.00      0.00       250\n",
      "           8       0.00      0.00      0.00       121\n",
      "           9       0.00      0.00      0.00       191\n",
      "          10       0.00      0.00      0.00        86\n",
      "          11       0.00      0.00      0.00        69\n",
      "          12       0.00      0.00      0.00        37\n",
      "          13       0.00      0.00      0.00       235\n",
      "          14       0.00      0.00      0.00       125\n",
      "          15       0.00      0.00      0.00       184\n",
      "          16       0.00      0.00      0.00       177\n",
      "          17       0.00      0.00      0.00       128\n",
      "          18       0.00      0.00      0.00        65\n",
      "          19       0.00      0.00      0.00        87\n",
      "          20       0.00      0.00      0.00        89\n",
      "          21       0.00      0.00      0.00        49\n",
      "          22       0.00      0.00      0.00        85\n",
      "          23       0.00      0.00      0.00       101\n",
      "          24       0.00      0.00      0.00       228\n",
      "          25       0.00      0.00      0.00       174\n",
      "          26       0.00      0.00      0.00       292\n",
      "          27       0.00      0.00      0.00       145\n",
      "          28       0.00      0.00      0.00         0\n",
      "          29       0.00      0.00      0.00        84\n",
      "          30       0.29      0.60      0.39       120\n",
      "          31       0.00      0.00      0.00        49\n",
      "          32       0.11      0.27      0.16       169\n",
      "          33       0.00      0.00      0.00        91\n",
      "          34       0.00      0.00      0.00        97\n",
      "          35       0.00      0.00      0.00       100\n",
      "          36       0.00      0.00      0.00       127\n",
      "          37       0.17      0.24      0.20       149\n",
      "          38       0.00      0.00      0.00       271\n",
      "          39       0.00      0.00      0.00       379\n",
      "          40       0.00      0.00      0.00       110\n",
      "          41       0.21      0.18      0.19       390\n",
      "          42       0.24      0.08      0.12       155\n",
      "          43       0.00      0.00      0.00       181\n",
      "          44       0.00      0.00      0.00       153\n",
      "          45       0.23      0.13      0.17       314\n",
      "          46       0.00      0.00      0.00       103\n",
      "          47       0.00      0.00      0.00        76\n",
      "          48       0.00      0.00      0.00        98\n",
      "          49       0.00      0.00      0.00        85\n",
      "          50       0.22      0.10      0.14        71\n",
      "          51       0.00      0.00      0.00        81\n",
      "          52       0.00      0.00      0.00        51\n",
      "          53       0.34      0.15      0.21       153\n",
      "          54       0.00      0.00      0.00        62\n",
      "          55       0.00      0.00      0.00       124\n",
      "          56       0.22      0.48      0.30       580\n",
      "          57       0.00      0.00      0.00       195\n",
      "          58       0.00      0.00      0.00       172\n",
      "          59       0.00      0.00      0.00       149\n",
      "          60       0.27      0.60      0.38       501\n",
      "          61       0.23      0.42      0.29       149\n",
      "          62       0.00      0.00      0.00       207\n",
      "          63       0.00      0.00      0.00       183\n",
      "          64       0.00      0.00      0.00        88\n",
      "          65       0.00      0.00      0.00       145\n",
      "          66       0.00      0.00      0.00       106\n",
      "          67       0.00      0.00      0.00       214\n",
      "          68       0.00      0.00      0.00        54\n",
      "          69       0.00      0.00      0.00       115\n",
      "          70       0.00      0.00      0.00         8\n",
      "          71       0.15      0.25      0.19       187\n",
      "          72       0.00      0.00      0.00       101\n",
      "          73       0.00      0.00      0.00       230\n",
      "          74       0.00      0.00      0.00       204\n",
      "          75       0.00      0.00      0.00       137\n",
      "          76       0.00      0.00      0.00        28\n",
      "          77       0.00      0.00      0.00        94\n",
      "          78       0.00      0.00      0.00         9\n",
      "          79       0.00      0.00      0.00        34\n",
      "\n",
      "   micro avg       0.37      0.27      0.32     14630\n",
      "   macro avg       0.04      0.06      0.05     14630\n",
      "weighted avg       0.15      0.27      0.19     14630\n",
      " samples avg       0.41      0.27      0.30     14630\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ee7b197-2023-4440-ae41-ec4dab1e6ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[178, 205, 350,   0,  10,  45, 164,   0,   0,   0],\n",
       "       [105, 212, 444,   0,   3,  11,  33,   0,   0,   0],\n",
       "       [139,  68, 701,   0,  12,  35, 119,   0,   0,   0],\n",
       "       [ 97,  60, 197,   0,   3,  13,  67,   0,   0,   0],\n",
       "       [ 36,  11,  81,   0,   7, 101, 132,   0,   0,   0],\n",
       "       [ 18,   3,  50,   0,   4, 117,  30,   0,   0,   0],\n",
       "       [ 78,  20, 118,   0,   9,  57, 217,   0,   0,   0],\n",
       "       [ 36,  10,  77,   0,   3,  11, 145,   0,   0,   0],\n",
       "       [ 11,   2,  13,   0,   0,   5,  55,   0,   0,   0],\n",
       "       [ 35,  35,  75,   0,   1,  38,  40,   0,   0,   0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_true, Y_pred).shape)\n",
    "confusion_matrix(y_true, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d6b3a0f-68d1-4367-869b-88d3273d19d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model0709/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"model0709\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d55b993d-a08c-407f-8bdf-2357948123d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "datagen= ImageDataGenerator(featurewise_center=True, fill_mode=\"nearest\")\n",
    "train = datagen.flow(X, Y, batch_size=64)\n",
    "len(train.next()[0])\n",
    "\n",
    "model.fit(datagen.flow(X, Y, batch_size=100), validation_data = datagen.flow(X_test, Y_test,\n",
    "         batch_size=32), steps_per_epoch=len(X) / 100, epochs=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "887c4845-2625-4dd6-9521-8af698dd5994",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataGen(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, coco, root_dir, set_name, image_ids, batch_size = 64 , input_size= (224, 224, 3),\n",
    "                 shuffle=True):\n",
    "        \n",
    "        self.image_ids = image_ids\n",
    "        self.indexes = np.arange(len(self.image_ids))\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.shuffle = shuffle\n",
    "        self.root_dir = root_dir\n",
    "        self.set_name = set_name\n",
    "        self.coco = coco\n",
    "       \n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __get_input(self, image_index):\n",
    "        \n",
    "        \n",
    "        image_info = coco.loadImgs(image_ids[image_index])[0]\n",
    "        path = os.path.join(self.root_dir, self.set_name, image_info['file_name'])\n",
    "        img = Image.open(path)\n",
    "        imgarray = np.array(img)\n",
    "        annotations_ids =coco.getAnnIds(imgIds=image_ids[image_index], iscrowd=False)\n",
    "  \n",
    "        if imgarray.ndim == 3 and annotations_ids:\n",
    "             \n",
    "                \n",
    "                coco_annotations = coco.loadAnns(annotations_ids)\n",
    "                \n",
    "                label = [0 for i in range(10)]\n",
    "                for index in range(len(coco_annotations)):\n",
    "                    \n",
    "                    category_id = coco_annotations[index]['category_id']\n",
    "                \n",
    "                    for c,d in category_dict2:\n",
    "                        if c == category_id:\n",
    "                            label[d] = 1\n",
    "               \n",
    "                return imgarray, label\n",
    "    \n",
    "    def __getoutput__(self):\n",
    "        \n",
    "        X = []\n",
    "        Y = []\n",
    "        for image_index in range(len(self.image_ids)):\n",
    "             if self.__get_input(image_index) is not None :\n",
    "                 X.append(self.__get_input(image_index)[0])\n",
    "                 Y.append(self.__get_input(image_index)[1])\n",
    "                \n",
    "        return np.asarray(X), np.asarray(Y)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "         \n",
    "        X, Y = self.__getoutput__()\n",
    "        \n",
    "        \n",
    "        batch_x = X[idx * self.batch_size:(idx + 1) *\n",
    "        self.batch_size]\n",
    "        batch_y = Y[idx * self.batch_size:(idx + 1) *\n",
    "        self.batch_size]\n",
    "\n",
    "        return batch_x, batch_y\n",
    "    \n",
    "    def __len__(self):\n",
    "          return int(np.floor(len(self.image_ids) / self.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ab3a43-fec7-4783-a0e4-4764207d5741",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datagen.flow(X, Y, batch_size=64)\n",
    "model.fit(datagen.flow(X, Y, batch_size=64), validation_data = datagen.flow(X_test, Y_test,\n",
    "         batch_size=64), steps_per_epoch=len(X) / 64, epochs=10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dcc4fd28-754f-4aa6-a607-250197b4fd39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09642872, 0.00162802, 0.01660121, 0.01321321, 0.16993096,\n",
       "       0.41670942, 0.20290275, 0.02421168, 0.02415303, 0.03422097],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc5df51c-9f91-4062-84a2-088420aa3646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed950c6f-c8c1-4599-bc6e-8e545645dbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datagen.flow(X, Y, batch_size=64)\n",
    "len(train.next()[0])\n",
    "\n",
    "len(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafefcca-3ada-4cdf-8436-25428674e91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.fit(datagen.flow(X, Y, batch_size=100), validation_data = datagen.flow(X_test, Y_test,\n",
    "         batch_size=32), steps_per_epoch=len(X) / 100, epochs=1)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d908150-fe3a-4f29-9497-aff98e12de68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(781, 78)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_ids = coco.getImgIds()\n",
    "image_ids2 = coco2.getImgIds()\n",
    "train_generator = DataGen(image_ids = image_ids[:50000], root_dir='../datasets/coco_2017/images/', \n",
    "        set_name='train2017_resize224/', coco= coco) \n",
    "\n",
    "validation_generator = DataGen(image_ids = image_ids2, root_dir='../datasets/coco_2017/images/', \n",
    "        set_name='val2017_resize224/', coco = coco2) \n",
    "\n",
    "len(train_generator), len(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0008dcf-20a0-4ae0-a63f-e26724b1ba47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "compute_steps_per_epoch = lambda x: int(math.ceil(1. * x / 64))\n",
    "model.fit_generator(generator=train_generator,\n",
    "         validation_data=validation_generator,   epochs = 5, use_multiprocessing=True,\n",
    "                    workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c72040a-602b-49ea-a262-680274f91ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a15bce1-cf6a-46e9-a3dc-472cc2b07e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((987, 224, 224, 3), (987, 10))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.asarray(X)\n",
    "Y = np.asarray(Y)\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d787388e-cf3c-4c25-b43c-c9e5a8329531",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for image_index in range(len(image_ids[:1000])):\n",
    "    \n",
    "    if __get_input(image_index) is not None:\n",
    "        X.append(__get_input(image_index)[0])\n",
    "        Y.append(__get_input(image_index)[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43ceafd7-1080-4b5e-93c9-d383fc2c16eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __get_input(image_index):\n",
    "        \n",
    "        \n",
    "        image_info = coco.loadImgs(image_ids[image_index])[0]\n",
    "        path = os.path.join(root_dir, set_name, image_info['file_name'])\n",
    "        img = Image.open(path)\n",
    "        imgarray = np.array(img)\n",
    "        annotations_ids =coco.getAnnIds(imgIds=image_ids[image_index], iscrowd=False)\n",
    "    \n",
    "            \n",
    "        if imgarray.ndim == 3 and annotations_ids:\n",
    "             \n",
    "                \n",
    "                coco_annotations = coco.loadAnns(annotations_ids)\n",
    "                \n",
    "                label = [0 for i in range(10)]\n",
    "                for index in range(len(coco_annotations)):\n",
    "                    \n",
    "                    category_id = coco_annotations[index]['category_id']\n",
    "                \n",
    "                    for c,d in category_dict2:\n",
    "                        if c == category_id:\n",
    "                            label[d] = 1\n",
    "               \n",
    "                return imgarray, label\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f46864-4b3c-44ec-aa17-0f785072152e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
