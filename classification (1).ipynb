{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cce02682-baca-4b2d-bea7-eddc68743d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6922 images belonging to 6 classes.\n",
      "Found 1725 images belonging to 6 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "generator = ImageDataGenerator(rescale=1./255, validation_split = 0.2)\n",
    "directory = '../Suhyun/ar/flowers'\n",
    "\n",
    "\n",
    "# train_generator = generator.flow_from_directory(\n",
    "#      directory,\n",
    "#     target_size = (224,224),\n",
    "#     batch_size = 10)\n",
    "\n",
    "\n",
    "train_dataset = generator.flow_from_directory(batch_size=32,\n",
    "                                                 directory = directory,\n",
    "                                                 shuffle=True,\n",
    "                                                 target_size=(224, 224), \n",
    "                                                 subset=\"training\",\n",
    "                                                 class_mode='categorical')\n",
    "\n",
    "validation_dataset = generator.flow_from_directory(batch_size=32,\n",
    "                                                 directory = directory,\n",
    "                                                 shuffle=True,\n",
    "                                                 target_size=(224, 224), \n",
    "                                                 subset=\"validation\",\n",
    "                                                 class_mode='categorical')\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f36ff29-d8a3-4cee-bf7a-000d8c68d494",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(nrows=1,ncols=10,figsize=(20,20))\n",
    "for i in range(10):\n",
    "    ax[i].imshow(train_dataset[i])\n",
    "    ax[i].axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65c0443d-bfdf-4df1-be8e-55dce465daff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_swish(features):\n",
    "\n",
    "  \n",
    "  features = tf.convert_to_tensor(features)\n",
    "  fdtype = features.dtype\n",
    "  return features * tf.nn.relu6(features + tf.cast(3., fdtype)) * (1. / 6.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2157eb66-3576-4d42-91a2-dd0a8b4f1356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def se_block(inputs, ch, ratio=16):\n",
    "\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(inputs)\n",
    "    x = tf.keras.layers.Dense(ch//ratio, activation='relu')(x)\n",
    "    y = tf.keras.layers.Dense(ch, activation='sigmoid')(x)\n",
    "    y = tf.keras.layers.multiply([inputs, y])\n",
    "    out = hard_swish(y)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8bf2a62-5cd4-4e18-b21d-c0a486aa3e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dep_bn(inputs, filter : int, kernel :int, stride: int):\n",
    "\n",
    "  y = tf.keras.layers.Conv2D(filters = filter, kernel_size= kernel, strides= stride, padding= 'same')(inputs)\n",
    "  bn = tf.keras.layers.BatchNormalization(axis = 1)(y)\n",
    "  out = tf.nn.relu6(bn)\n",
    "  \n",
    "  return out\n",
    "\n",
    "\n",
    "def Inverted_residual_SEblock(x,  hs: bool, se: bool , filters, kernel, strides,  expansion_ratio ):\n",
    "\n",
    "\n",
    "    #pointwise\n",
    "    y = tf.keras.layers.Conv2D(filters = x.get_shape().as_list()[-1]*expansion_ratio, kernel_size=  1, strides = 1, padding= 'same')(x)\n",
    "    bn = tf.keras.layers.BatchNormalization(axis = 1)(y)\n",
    "    if hs:\n",
    "        y_p = hard_swish(bn)\n",
    "    else:\n",
    "        y_p = tf.nn.relu6(bn)\n",
    "    \n",
    "    \n",
    "    #depthwise\n",
    "    y = tf.keras.layers.DepthwiseConv2D(kernel_size=  kernel, strides= strides, padding= 'same', depth_multiplier = 1)(y_p)\n",
    "    bn = tf.keras.layers.BatchNormalization(axis = 1)(y)\n",
    "    if hs:\n",
    "        out = hard_swish(bn)\n",
    "    else:\n",
    "        out = tf.nn.relu6(bn)\n",
    "   \n",
    "    \n",
    "    if se: \n",
    "        channel = out.get_shape().as_list()[-1]\n",
    "        out = se_block(out, channel)\n",
    "\n",
    "    \n",
    "    #pointwise\n",
    "    y = tf.keras.layers.Conv2D(filters = filters, kernel_size=  1, strides = 1, padding= 'same')(out)\n",
    "    bn = tf.keras.layers.BatchNormalization(axis = 1)(y)\n",
    "    if hs:\n",
    "        y_p = hard_swish(bn)\n",
    "    else:\n",
    "        y_p = tf.nn.relu6(bn)\n",
    "        \n",
    "        \n",
    "    \n",
    "    if strides == 1:\n",
    "        if x.shape[3] != filters : \n",
    "           x = tf.keras.layers.Conv2D(filters = filters, kernel_size = 1, strides = strides, padding = \"same\")(x)\n",
    "        out  = tf.keras.layers.Add()([x, y_p])\n",
    "   \n",
    "    \n",
    "\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "76efa1e0-4fab-4661-827e-aef6f6cd79cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mobilenetV3(inputs):\n",
    "\n",
    "   x = dep_bn(inputs, 16, 3, 2)\n",
    "   x = Inverted_residual_SEblock(x, False, False, 16, 3, 1,1)\n",
    "\n",
    "   x = Inverted_residual_SEblock(x, False, False, 24, 3, 2, 4)\n",
    "   x = Inverted_residual_SEblock(x, False, False, 24, 3, 1, 3)\n",
    "   \n",
    "   x = Inverted_residual_SEblock(x, False, True, 40, 5, 2, 3)\n",
    "   x = Inverted_residual_SEblock(x, False, True, 40, 5, 1, 3)\n",
    "   x = Inverted_residual_SEblock(x, False, True, 40, 5, 1, 3)\n",
    "\n",
    "   x = Inverted_residual_SEblock(x, True, False, 80, 3, 2, 6)\n",
    "   x = Inverted_residual_SEblock(x, True, False, 80, 3, 1, 2.5)\n",
    "   x = Inverted_residual_SEblock(x, True, False, 80, 3, 1, 184/80)\n",
    "   x = Inverted_residual_SEblock(x, True, False, 80, 3, 1, 184/80)\n",
    "    \n",
    "   x = Inverted_residual_SEblock(x, True, True, 112, 3, 1, 6)\n",
    "   x = Inverted_residual_SEblock(x, True, True, 112, 3, 1, 6)\n",
    "    \n",
    "   x = Inverted_residual_SEblock(x, True, True, 160, 5, 2, 6)\n",
    "   \n",
    "   x = Inverted_residual_SEblock(x, True, True, 160, 5, 1, 6)\n",
    "   x = Inverted_residual_SEblock(x, True, True, 160, 5, 1, 6)\n",
    "   x = dep_bn(x, 960, 1, 1)\n",
    "   \n",
    "   t = tf.keras.layers.AveragePooling2D(1)(x)\n",
    "   t = tf.keras.layers.Flatten()(t)\n",
    "   outputs = tf.keras.layers.Dense(6, activation='softmax')(t)\n",
    "   return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c2bee373-8715-45c2-9687-9a70ad273db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.applications.MobileNetV3Large()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3a12258d-9639-44a6-84f6-12daca3e3f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(224,224,3))\n",
    "outputs = create_mobilenetV3(inputs)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(\n",
    "        optimizer=opt,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4ba1050e-08df-470f-a528-a808487dd7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "217/217 [==============================] - 24s 97ms/step - loss: 2.0177 - accuracy: 0.4840 - val_loss: 1.4992 - val_accuracy: 0.5009\n",
      "Epoch 2/100\n",
      "217/217 [==============================] - 21s 95ms/step - loss: 1.6932 - accuracy: 0.4877 - val_loss: 1.5438 - val_accuracy: 0.5009\n",
      "Epoch 3/100\n",
      "217/217 [==============================] - 21s 95ms/step - loss: 1.5161 - accuracy: 0.4925 - val_loss: 1.4928 - val_accuracy: 0.5009\n",
      "Epoch 4/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.5362 - accuracy: 0.4939 - val_loss: 1.5158 - val_accuracy: 0.5009\n",
      "Epoch 5/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.5064 - accuracy: 0.4928 - val_loss: 1.5106 - val_accuracy: 0.5009\n",
      "Epoch 6/100\n",
      "217/217 [==============================] - 21s 95ms/step - loss: 1.4870 - accuracy: 0.4918 - val_loss: 1.4485 - val_accuracy: 0.5078\n",
      "Epoch 7/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.4419 - accuracy: 0.4903 - val_loss: 1.3950 - val_accuracy: 0.5026\n",
      "Epoch 8/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.4089 - accuracy: 0.4905 - val_loss: 1.4321 - val_accuracy: 0.5026\n",
      "Epoch 9/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.3964 - accuracy: 0.4899 - val_loss: 1.4429 - val_accuracy: 0.5136\n",
      "Epoch 10/100\n",
      "217/217 [==============================] - 21s 95ms/step - loss: 1.3956 - accuracy: 0.4932 - val_loss: 1.4422 - val_accuracy: 0.5009\n",
      "Epoch 11/100\n",
      "217/217 [==============================] - 21s 95ms/step - loss: 1.3888 - accuracy: 0.4948 - val_loss: 1.4072 - val_accuracy: 0.5009\n",
      "Epoch 12/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.3926 - accuracy: 0.4899 - val_loss: 1.4272 - val_accuracy: 0.5009\n",
      "Epoch 13/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.3629 - accuracy: 0.4952 - val_loss: 1.4069 - val_accuracy: 0.5009\n",
      "Epoch 14/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.3705 - accuracy: 0.4968 - val_loss: 1.3726 - val_accuracy: 0.5281\n",
      "Epoch 15/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.3577 - accuracy: 0.4942 - val_loss: 1.4121 - val_accuracy: 0.5113\n",
      "Epoch 16/100\n",
      "217/217 [==============================] - 21s 95ms/step - loss: 1.3696 - accuracy: 0.4983 - val_loss: 1.3770 - val_accuracy: 0.5009\n",
      "Epoch 17/100\n",
      "217/217 [==============================] - 21s 95ms/step - loss: 1.3570 - accuracy: 0.4961 - val_loss: 1.3758 - val_accuracy: 0.5009\n",
      "Epoch 18/100\n",
      "217/217 [==============================] - 21s 95ms/step - loss: 1.3438 - accuracy: 0.4981 - val_loss: 1.3901 - val_accuracy: 0.5009\n",
      "Epoch 19/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.3393 - accuracy: 0.4987 - val_loss: 1.4002 - val_accuracy: 0.5009\n",
      "Epoch 20/100\n",
      "217/217 [==============================] - 21s 95ms/step - loss: 1.3432 - accuracy: 0.4973 - val_loss: 1.3500 - val_accuracy: 0.5009\n",
      "Epoch 21/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.3428 - accuracy: 0.4975 - val_loss: 1.3261 - val_accuracy: 0.5009\n",
      "Epoch 22/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.3675 - accuracy: 0.4990 - val_loss: 1.3340 - val_accuracy: 0.5009\n",
      "Epoch 23/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.3352 - accuracy: 0.4977 - val_loss: 1.3663 - val_accuracy: 0.5009\n",
      "Epoch 24/100\n",
      "217/217 [==============================] - 21s 95ms/step - loss: 1.3382 - accuracy: 0.4994 - val_loss: 1.3458 - val_accuracy: 0.5009\n",
      "Epoch 25/100\n",
      "217/217 [==============================] - 21s 95ms/step - loss: 1.3343 - accuracy: 0.4994 - val_loss: 1.4011 - val_accuracy: 0.5009\n",
      "Epoch 26/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.3409 - accuracy: 0.4980 - val_loss: 1.4221 - val_accuracy: 0.5009\n",
      "Epoch 27/100\n",
      "217/217 [==============================] - 21s 95ms/step - loss: 1.3280 - accuracy: 0.4984 - val_loss: 1.3529 - val_accuracy: 0.5009\n",
      "Epoch 28/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.3283 - accuracy: 0.4962 - val_loss: 1.4040 - val_accuracy: 0.5009\n",
      "Epoch 29/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.3355 - accuracy: 0.4993 - val_loss: 1.3921 - val_accuracy: 0.5478\n",
      "Epoch 30/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.3223 - accuracy: 0.4986 - val_loss: 1.3121 - val_accuracy: 0.5316\n",
      "Epoch 31/100\n",
      "217/217 [==============================] - 21s 95ms/step - loss: 1.3225 - accuracy: 0.4980 - val_loss: 1.3795 - val_accuracy: 0.5009\n",
      "Epoch 32/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.3201 - accuracy: 0.4991 - val_loss: 1.3777 - val_accuracy: 0.5159\n",
      "Epoch 33/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.3222 - accuracy: 0.4980 - val_loss: 1.3488 - val_accuracy: 0.5009\n",
      "Epoch 34/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.3237 - accuracy: 0.4987 - val_loss: 1.3784 - val_accuracy: 0.5055\n",
      "Epoch 35/100\n",
      "217/217 [==============================] - 21s 95ms/step - loss: 1.3230 - accuracy: 0.4996 - val_loss: 1.3512 - val_accuracy: 0.5032\n",
      "Epoch 36/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.3354 - accuracy: 0.4991 - val_loss: 1.3381 - val_accuracy: 0.5107\n",
      "Epoch 37/100\n",
      "217/217 [==============================] - 21s 95ms/step - loss: 1.3188 - accuracy: 0.4980 - val_loss: 1.3801 - val_accuracy: 0.5287\n",
      "Epoch 38/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.3198 - accuracy: 0.4987 - val_loss: 1.3481 - val_accuracy: 0.5072\n",
      "Epoch 39/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.3224 - accuracy: 0.4988 - val_loss: 1.3268 - val_accuracy: 0.5020\n",
      "Epoch 40/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.3218 - accuracy: 0.4984 - val_loss: 1.5221 - val_accuracy: 0.5183\n",
      "Epoch 41/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.3128 - accuracy: 0.4994 - val_loss: 1.3667 - val_accuracy: 0.5009\n",
      "Epoch 42/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.3157 - accuracy: 0.5006 - val_loss: 1.3372 - val_accuracy: 0.5009\n",
      "Epoch 43/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.3196 - accuracy: 0.4954 - val_loss: 1.3383 - val_accuracy: 0.5049\n",
      "Epoch 44/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.3286 - accuracy: 0.4991 - val_loss: 1.3606 - val_accuracy: 0.5009\n",
      "Epoch 45/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.3202 - accuracy: 0.4977 - val_loss: 1.4022 - val_accuracy: 0.5183\n",
      "Epoch 46/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.3196 - accuracy: 0.4984 - val_loss: 1.3784 - val_accuracy: 0.5020\n",
      "Epoch 47/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.3149 - accuracy: 0.4986 - val_loss: 1.3769 - val_accuracy: 0.5009\n",
      "Epoch 48/100\n",
      "217/217 [==============================] - 21s 95ms/step - loss: 1.3085 - accuracy: 0.4987 - val_loss: 1.3595 - val_accuracy: 0.5090\n",
      "Epoch 49/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.3086 - accuracy: 0.4988 - val_loss: 1.4336 - val_accuracy: 0.5067\n",
      "Epoch 50/100\n",
      "217/217 [==============================] - 21s 95ms/step - loss: 1.3085 - accuracy: 0.4993 - val_loss: 1.3559 - val_accuracy: 0.5009\n",
      "Epoch 51/100\n",
      "217/217 [==============================] - 21s 95ms/step - loss: 1.3031 - accuracy: 0.4968 - val_loss: 1.3567 - val_accuracy: 0.5009\n",
      "Epoch 52/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.3038 - accuracy: 0.4997 - val_loss: 1.3516 - val_accuracy: 0.5043\n",
      "Epoch 53/100\n",
      "217/217 [==============================] - 21s 95ms/step - loss: 1.3017 - accuracy: 0.4988 - val_loss: 1.3746 - val_accuracy: 0.5014\n",
      "Epoch 54/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.2980 - accuracy: 0.4991 - val_loss: 1.4034 - val_accuracy: 0.5009\n",
      "Epoch 55/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.2983 - accuracy: 0.4988 - val_loss: 1.3217 - val_accuracy: 0.5009\n",
      "Epoch 56/100\n",
      "217/217 [==============================] - 21s 95ms/step - loss: 1.3110 - accuracy: 0.4951 - val_loss: 1.4034 - val_accuracy: 0.5014\n",
      "Epoch 57/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.2847 - accuracy: 0.4983 - val_loss: 1.3378 - val_accuracy: 0.5014\n",
      "Epoch 58/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.2678 - accuracy: 0.4970 - val_loss: 1.4168 - val_accuracy: 0.5003\n",
      "Epoch 59/100\n",
      "217/217 [==============================] - 21s 95ms/step - loss: 1.2659 - accuracy: 0.4973 - val_loss: 1.3561 - val_accuracy: 0.5009\n",
      "Epoch 60/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.2567 - accuracy: 0.4955 - val_loss: 1.3758 - val_accuracy: 0.5009\n",
      "Epoch 61/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.2477 - accuracy: 0.4967 - val_loss: 1.3390 - val_accuracy: 0.5003\n",
      "Epoch 62/100\n",
      "217/217 [==============================] - 21s 95ms/step - loss: 1.2473 - accuracy: 0.4975 - val_loss: 1.3256 - val_accuracy: 0.4991\n",
      "Epoch 63/100\n",
      "217/217 [==============================] - 21s 95ms/step - loss: 1.2393 - accuracy: 0.4977 - val_loss: 1.3742 - val_accuracy: 0.5125\n",
      "Epoch 64/100\n",
      "217/217 [==============================] - 21s 95ms/step - loss: 1.2350 - accuracy: 0.4971 - val_loss: 1.3253 - val_accuracy: 0.4997\n",
      "Epoch 65/100\n",
      "217/217 [==============================] - 21s 95ms/step - loss: 1.2241 - accuracy: 0.5012 - val_loss: 1.3525 - val_accuracy: 0.4522\n",
      "Epoch 66/100\n",
      "217/217 [==============================] - 21s 95ms/step - loss: 1.2096 - accuracy: 0.4981 - val_loss: 1.3501 - val_accuracy: 0.4974\n",
      "Epoch 67/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.2139 - accuracy: 0.5016 - val_loss: 1.6046 - val_accuracy: 0.5055\n",
      "Epoch 68/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.2009 - accuracy: 0.4997 - val_loss: 1.4050 - val_accuracy: 0.3038\n",
      "Epoch 69/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.2007 - accuracy: 0.5066 - val_loss: 1.4506 - val_accuracy: 0.4609\n",
      "Epoch 70/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.1869 - accuracy: 0.5092 - val_loss: 1.3478 - val_accuracy: 0.4817\n",
      "Epoch 71/100\n",
      "217/217 [==============================] - 21s 95ms/step - loss: 1.1962 - accuracy: 0.5068 - val_loss: 1.3584 - val_accuracy: 0.3768\n",
      "Epoch 72/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.1721 - accuracy: 0.5140 - val_loss: 1.3775 - val_accuracy: 0.4116\n",
      "Epoch 73/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.1729 - accuracy: 0.5098 - val_loss: 1.3692 - val_accuracy: 0.3386\n",
      "Epoch 74/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.1759 - accuracy: 0.5090 - val_loss: 1.3446 - val_accuracy: 0.4139\n",
      "Epoch 75/100\n",
      "217/217 [==============================] - 21s 95ms/step - loss: 1.1567 - accuracy: 0.5144 - val_loss: 1.3840 - val_accuracy: 0.4765\n",
      "Epoch 76/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.1522 - accuracy: 0.5114 - val_loss: 1.5722 - val_accuracy: 0.2417\n",
      "Epoch 77/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.1507 - accuracy: 0.5215 - val_loss: 1.5397 - val_accuracy: 0.2643\n",
      "Epoch 78/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.1412 - accuracy: 0.5074 - val_loss: 1.4515 - val_accuracy: 0.3472\n",
      "Epoch 79/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.1406 - accuracy: 0.5166 - val_loss: 1.4425 - val_accuracy: 0.3194\n",
      "Epoch 80/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.1313 - accuracy: 0.5218 - val_loss: 1.5517 - val_accuracy: 0.2713\n",
      "Epoch 81/100\n",
      "217/217 [==============================] - 21s 95ms/step - loss: 1.1268 - accuracy: 0.5201 - val_loss: 1.4229 - val_accuracy: 0.4209\n",
      "Epoch 82/100\n",
      "217/217 [==============================] - 21s 95ms/step - loss: 1.1212 - accuracy: 0.5196 - val_loss: 1.5225 - val_accuracy: 0.3403\n",
      "Epoch 83/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.1152 - accuracy: 0.5282 - val_loss: 1.3919 - val_accuracy: 0.3965\n",
      "Epoch 84/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.1283 - accuracy: 0.5170 - val_loss: 1.4043 - val_accuracy: 0.4064\n",
      "Epoch 85/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.1113 - accuracy: 0.5261 - val_loss: 1.3614 - val_accuracy: 0.4272\n",
      "Epoch 86/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.1088 - accuracy: 0.5157 - val_loss: 1.6482 - val_accuracy: 0.2864\n",
      "Epoch 87/100\n",
      "217/217 [==============================] - 21s 95ms/step - loss: 1.1020 - accuracy: 0.5283 - val_loss: 1.4954 - val_accuracy: 0.3559\n",
      "Epoch 88/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.0970 - accuracy: 0.5254 - val_loss: 1.5422 - val_accuracy: 0.3316\n",
      "Epoch 89/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.1000 - accuracy: 0.5289 - val_loss: 1.5157 - val_accuracy: 0.3223\n",
      "Epoch 90/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.0871 - accuracy: 0.5234 - val_loss: 1.7027 - val_accuracy: 0.2800\n",
      "Epoch 91/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.0902 - accuracy: 0.5238 - val_loss: 1.5541 - val_accuracy: 0.3374\n",
      "Epoch 92/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.0794 - accuracy: 0.5292 - val_loss: 1.6209 - val_accuracy: 0.3113\n",
      "Epoch 93/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.0783 - accuracy: 0.5267 - val_loss: 1.5255 - val_accuracy: 0.3420\n",
      "Epoch 94/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.0769 - accuracy: 0.5285 - val_loss: 1.6793 - val_accuracy: 0.2609\n",
      "Epoch 95/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.0724 - accuracy: 0.5279 - val_loss: 1.4761 - val_accuracy: 0.3403\n",
      "Epoch 96/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.0725 - accuracy: 0.5238 - val_loss: 1.7173 - val_accuracy: 0.2748\n",
      "Epoch 97/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.0659 - accuracy: 0.5285 - val_loss: 1.7408 - val_accuracy: 0.2649\n",
      "Epoch 98/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.0642 - accuracy: 0.5298 - val_loss: 1.4319 - val_accuracy: 0.4186\n",
      "Epoch 99/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.0519 - accuracy: 0.5287 - val_loss: 1.6630 - val_accuracy: 0.5038\n",
      "Epoch 100/100\n",
      "217/217 [==============================] - 21s 96ms/step - loss: 1.0570 - accuracy: 0.5315 - val_loss: 1.7152 - val_accuracy: 0.2713\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f07e9e1ee50>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, validation_data=validation_dataset, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cf203948-39ff-46c4-af9f-48350390c9ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32,)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def making_ypred(predictions):\n",
    "    pred2s = []\n",
    "    for pred in predictions:\n",
    "        pred2s.append(np.argmax(pred))\n",
    "    return pred2s\n",
    "\n",
    "predictions = model.predict(validation_dataset[0][0])\n",
    "y_pred = np.asarray(making_ypred(predictions))\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c95d34fb-7ff4-446c-a324-3b25b408ab1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_output(prediction) :\n",
    "    \n",
    "    index_list = []\n",
    "    for pred in prediction:\n",
    "        i = np.argmax(pred)\n",
    "        index_list.append(i)\n",
    "    return index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8f61622c-be31-4c83-9df2-690be1a3e5b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32,)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(index_output(predictions)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b515e953-7f7f-49ef-9c67-3a84612e255c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32,)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_true =[]\n",
    "for y in y_true:\n",
    "    Y_true.append(np.where(y==1))\n",
    "Y_true = np.squeeze(np.asarray(Y_true))\n",
    "Y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6aa7727a-bafe-4c03-bdcd-e9153859466e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.67      0.25         3\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.33      0.35      0.34        17\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       1.00      0.20      0.33         5\n",
      "           5       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.28        32\n",
      "   macro avg       0.25      0.20      0.15        32\n",
      "weighted avg       0.35      0.28      0.26        32\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_true = validation_dataset[0][1]\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(Y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
